/* // bicubic_weight_comparison.js
const tf = require("@tensorflow/tfjs-node");
const fs = require("fs");
const path = require("path");
const { promisify } = require("util");
const PNG = require("pngjs").PNG;

// ===================== é…ç½® =====================
const learn_rate = "adaptive-1e-3-30"; // å¯é…ç½®ä¸ºå‘½ä»¤è¡Œå‚æ•°
const OUTPUT_DIR = path.join("cp_model", learn_rate);

// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
if (!fs.existsSync(OUTPUT_DIR)) {
  fs.mkdirSync(OUTPUT_DIR, { recursive: true });
}

const CONFIG = {
  metadataPath: "./data/test/metadata.json",
  directories: {
    lrImages: "./data/test/X/",
    offsets: "./data/test/offset/",
    gtWeights: "./data/test/Y/",
  },
  modelPath: `file://./model/${learn_rate}/model.json`,
  output: {
    sampleWeights: path.join(OUTPUT_DIR, "weight_sample.png"),
    gtHistogram: path.join(OUTPUT_DIR, "gt_weights_hist.png"),
    predHistogram: path.join(OUTPUT_DIR, "pred_weights_hist.png"),
    comparisonTable: path.join(OUTPUT_DIR, "comparison.txt"),
  },
};

// ===================== å·¥å…·å‡½æ•° =====================
const readDir = promisify(fs.readdir);
const readFile = promisify(fs.readFile);
const writeFile = promisify(fs.writeFile);

async function loadTensorWithHeader(filePath) {
  const buffer = await fs.promises.readFile(filePath);

  const header = {
    height: buffer.readUInt32LE(0),
    width: buffer.readUInt32LE(4),
    channels: buffer.readUInt32LE(8),
  };

  const dataBuffer = buffer.slice(12);
  const float32Data = new Float32Array(
    dataBuffer.buffer,
    dataBuffer.byteOffset,
    dataBuffer.byteLength / 4
  );

  return {
    tensor: tf.tensor3d(float32Data, [
      header.height,
      header.width,
      header.channels,
    ]),
    header,
  };
}

function validateTensor(tensor, header, filename) {
  const expectedSize = header.height * header.width * header.channels;
  if (tensor.size !== expectedSize) {
    throw new Error(
      `æ•°æ®éªŒè¯å¤±è´¥ ${filename}\né¢„æœŸ: ${expectedSize}\nå®é™…: ${tensor.size}`
    );
  }
}

// ===================== æ ¸å¿ƒé€»è¾‘ =====================
class WeightComparator {
  constructor(config) {
    this.config = config;
    this.model = null;
    this.metadata = null;
  }

  async initialize() {
    this.metadata = JSON.parse(await readFile(this.config.metadataPath));
    this.model = await tf.loadLayersModel(this.config.modelPath);
    console.log("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
  }

  async loadDataset() {
    const loadData = async (dir) => {
      const files = await readDir(dir);
      const tensorMap = new Map();

      for (const file of files.filter((f) => f.endsWith(".bin"))) {
        const filePath = path.join(dir, file);
        const { tensor, header } = await loadTensorWithHeader(filePath);
        validateTensor(tensor, header, file);
        tensorMap.set(path.parse(file).name, tensor);
      }
      return tensorMap;
    };

    const [images, offsets, weights] = await Promise.all([
      loadData(this.config.directories.lrImages),
      loadData(this.config.directories.offsets),
      loadData(this.config.directories.gtWeights),
    ]);

    return { images, offsets, weights };
  }

  async compareWeights(gtTensor, predTensor) {
    console.log("\nğŸ”¬ å¼€å§‹æƒé‡å¯¹æ¯”åˆ†æ");

    // å…¨å±€è¯¯å·®åˆ†æ
    const mse = tf.losses.meanSquaredError(gtTensor, predTensor);
    console.log(`ğŸ“‰ å…¨å±€MSE: ${mse.dataSync()[0].toExponential(3)}`);
    tf.dispose(mse);

    // é€šé“çº§å¯¹æ¯”
    const channelErrors = [];
    for (let c = 0; c < 16; c++) {
      const gtChannel = gtTensor.slice([0, 0, c], [-1, -1, 1]);
      const predChannel = predTensor.slice([0, 0, c], [-1, -1, 1]);
      const channelMSE = tf.losses.meanSquaredError(gtChannel, predChannel);
      channelErrors.push(channelMSE.dataSync()[0]);
      tf.dispose([gtChannel, predChannel, channelMSE]);
    }
    console.log("ğŸ“Š å„é€šé“MSE:");
    channelErrors.forEach((err, i) =>
      console.log(`é€šé“ ${i.toString().padStart(2)}: ${err.toExponential(3)}`)
    );

    // å¯è§†åŒ–å¯¹æ¯”
    await this.generateHistograms(gtTensor, predTensor);
    await this.samplePixelComparison(gtTensor, predTensor);
  }

  async generateHistograms(gtTensor, predTensor) {
    // åˆ›å»ºç›´æ–¹å›¾ç›®å½•
    const histDir = path.join(OUTPUT_DIR, "histograms");
    if (!fs.existsSync(histDir)) {
      fs.mkdirSync(histDir, { recursive: true });
    }

    await this.createHistogram(
      gtTensor,
      path.join(histDir, "gt_histogram.png")
    );
    await this.createHistogram(
      predTensor,
      path.join(histDir, "pred_histogram.png")
    );
  }

  async createHistogram(tensor, filename) {
    const data = await tensor.data();
    const bins = new Array(20).fill(0);

    data.forEach((v) => {
      const bin = Math.min(Math.floor(v * 20), 19);
      bins[bin]++;
    });

    const png = new PNG({ width: 800, height: 400, colorType: 2 });
    const maxCount = Math.max(...bins);

    bins.forEach((count, i) => {
      const barHeight = (count / maxCount) * 400;
      for (let y = 399; y >= 400 - barHeight; y--) {
        for (let x = i * 40; x < (i + 1) * 40; x++) {
          const idx = (y * 800 + x) * 3;
          png.data[idx] = 255; // çº¢è‰²é€šé“
          png.data[idx + 1] = 0; // ç»¿è‰²é€šé“
          png.data[idx + 2] = 0; // è“è‰²é€šé“
        }
      }
    });

    await new Promise((resolve) =>
      png.pack().pipe(fs.createWriteStream(filename)).on("finish", resolve)
    );
  }

  // ä¿®æ”¹ samplePixelComparison æ–¹æ³•ä¸­çš„è¿™éƒ¨åˆ†
  async samplePixelComparison(gtTensor, predTensor) {
    const sampleCoord = {
      x: Math.floor(gtTensor.shape[1] / 2),
      y: Math.floor(gtTensor.shape[0] / 2),
    };

    // ä¿®å¤æ•°ç»„è®¿é—®æ–¹å¼
    const gtValues = gtTensor
      .slice([sampleCoord.y, sampleCoord.x, 0], [1, 1, 16])
      .arraySync()
      .flat(2);
    const predValues = predTensor
      .slice([sampleCoord.y, sampleCoord.x, 0], [1, 1, 16])
      .arraySync()
      .flat(2);

    console.log(`\nğŸ” ä¸­å¿ƒç‚¹ (${sampleCoord.x},${sampleCoord.y}) æƒé‡å¯¹æ¯”:`);
    console.log("â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    console.log("â”‚ é€šé“ â”‚ çœŸå®æƒé‡          â”‚ é¢„æµ‹æƒé‡          â”‚ å·®å¼‚(%)   â”‚");
    console.log("â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

    gtValues.forEach((gt, i) => {
      const pred = predValues[i];
      const diff = (((pred - gt) / (Math.abs(gt) + 1e-8)) * 100).toFixed(2);
      console.log(
        `â”‚ ${i.toString().padStart(2)}  â”‚ ${gt
          .toExponential(4)
          .padEnd(15)} â”‚ ` +
          `${pred.toExponential(4).padEnd(15)} â”‚ ${diff.padStart(7)}% â”‚`
      );
    });
    console.log("â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    // ä¿å­˜å¯¹æ¯”ç»“æœåˆ°æ–‡ä»¶
    const tableContent = [
      "â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
      "â”‚ é€šé“ â”‚ çœŸå®æƒé‡          â”‚ é¢„æµ‹æƒé‡          â”‚ å·®å¼‚(%)   â”‚",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
      ...gtValues.map((gt, i) => {
        const pred = predValues[i];
        const diff = (((pred - gt) / (Math.abs(gt) + 1e-8)) * 100).toFixed(2);
        return (
          `â”‚ ${i.toString().padStart(2)}  â”‚ ${gt
            .toExponential(4)
            .padEnd(15)} â”‚ ` +
          `${pred.toExponential(4).padEnd(15)} â”‚ ${diff.padStart(7)}% â”‚`
        );
      }),
      "â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
    ].join("\n");

    await writeFile(CONFIG.output.comparisonTable, tableContent);
    console.log(`ğŸ“ å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜è‡³: ${CONFIG.output.comparisonTable}`);
  }
  async visualizeSampleWeights(tensor) {
    // åˆ›å»ºå¯è§†åŒ–ç›®å½•
    const visDir = path.join(OUTPUT_DIR, "visualizations");
    if (!fs.existsSync(visDir)) {
      fs.mkdirSync(visDir, { recursive: true });
    }

    const outputPath = path.join(visDir, "weight_samples");
    if (!fs.existsSync(outputPath)) {
      fs.mkdirSync(outputPath);
    }

    // ä¿å­˜å¤šä¸ªé€šé“çš„å¯è§†åŒ–ç»“æœ
    for (let c = 0; c < 3; c++) {
      // ç¤ºä¾‹ä¿å­˜å‰3ä¸ªé€šé“
      const channel = tensor.slice([0, 0, c], [-1, -1, 1]);
      const png = await this.tensorToPNG(channel);
      await writeFile(path.join(outputPath, `channel_${c}.png`), png);
      tf.dispose(channel);
    }
    console.log(`ğŸ–¼ï¸ å¤šé€šé“å¯è§†åŒ–å·²ä¿å­˜è‡³: ${outputPath}`);
  }

  async tensorToPNG(tensor) {
    const data = await tensor.data();
    const [height, width] = tensor.shape;

    const png = new PNG({ width, height, colorType: 2 });
    data.forEach((v, i) => {
      const val = Math.min(255, Math.max(0, v * 255));
      png.data[i * 3] = val; // R
      png.data[i * 3 + 1] = val; // G
      png.data[i * 3 + 2] = val; // B
    });

    return PNG.sync.write(png);
  }
  async execute() {
    try {
      await this.initialize();
      const { images, offsets, weights } = await this.loadDataset();

      const [sampleId] = Array.from(images.keys());
      const inputTensor = images.get(sampleId).expandDims(0);
      const offsetTensor = offsets.get(sampleId).expandDims(0);
      const gtTensor = weights.get(sampleId);

      const predTensor = this.model
        .predict([inputTensor, offsetTensor])
        .squeeze();
      console.log("ğŸ§  é¢„æµ‹å®Œæˆï¼Œå¼€å§‹åˆ†æ...");

      await this.compareWeights(gtTensor, predTensor);
      await this.visualizeSampleWeights(predTensor);

      tf.dispose([inputTensor, offsetTensor, gtTensor, predTensor]);
    } catch (error) {
      console.error("â€¼ï¸ æ‰§è¡Œå¤±è´¥:", error.message);
    }
  }

  async visualizeSampleWeights(tensor) {
    const sample = tensor.slice([0, 0, 0], [100, 100, 16]);
    const firstChannel = sample.slice([0, 0, 0], [100, 100, 1]);

    const png = new PNG({ width: 100, height: 100, colorType: 2 });
    const data = await firstChannel.data();

    data.forEach((v, i) => {
      const val = Math.min(255, Math.max(0, v * 255));
      png.data[i * 3] = val; // R
      png.data[i * 3 + 1] = val; // G
      png.data[i * 3 + 2] = val; // B
    });

    await new Promise((resolve) =>
      png
        .pack()
        .pipe(fs.createWriteStream(this.config.output.sampleWeights))
        .on("finish", resolve)
    );
    console.log(`ğŸ–¼ï¸ æƒé‡é‡‡æ ·å›¾å·²ä¿å­˜è‡³: ${this.config.output.sampleWeights}`);
  }
}

// ===================== æ‰§è¡Œå…¥å£ =====================
(async () => {
  try {
    // äºŒæ¬¡ç¡®è®¤è¾“å‡ºç›®å½•
    if (!fs.existsSync(OUTPUT_DIR)) {
      fs.mkdirSync(OUTPUT_DIR, { recursive: true });
      console.log(`ğŸ“‚ å·²åˆ›å»ºè¾“å‡ºç›®å½•: ${OUTPUT_DIR}`);
    }

    const comparator = new WeightComparator(CONFIG);
    await comparator.execute();
    console.log("ğŸ ç¨‹åºæ‰§è¡Œå®Œæˆ");

    // æ‰“å¼€ç»“æœç›®å½•ï¼ˆä»…é™macOSï¼‰
    if (process.platform === "darwin") {
      require("child_process").exec(`open ${path.resolve(OUTPUT_DIR)}`);
    }
  } catch (error) {
    console.error("â€¼ï¸ åˆå§‹åŒ–å¤±è´¥:", error.message);
    process.exit(1);
  }
})();
 */
const tf = require("@tensorflow/tfjs-node");
const fs = require("fs");
const path = require("path");
const { createCanvas } = require("@napi-rs/canvas"); // æ›´é«˜æ•ˆçš„å†…å­˜ç®¡ç†
const { promisify } = require("util");
const { pipeline } = require("stream/promises");
const PNG = require("pngjs").PNG;

// ===================== å¢å¼ºé…ç½® =====================
const CONFIG = {
  learnRate: "adaptive-1e-3-30",
  metadataPath: "./data/test/metadata.json",
  directories: {
    lrImages: "./data/test/X/",
    offsets: "./data/test/offset/",
    gtWeights: "./data/test/Y/",
  },
  modelPath: "file://./model/adaptive-1e-3-30/model.json",
  output: {
    root: "./analysis_results",
    histograms: "histograms",
    tables: "tables",
    visualizations: "visuals",
  },
  performance: {
    chunkSize: 1e5, // åˆ†å—å¤„ç†å¤§å°
    maxBins: 1000, // æœ€å¤§åˆ†ç®±æ•°
    canvasDPI: 300, // è¾“å‡ºåˆ†è¾¨ç‡
  },
};

// ===================== å·¥å…·å‡½æ•° =====================
const readDir = promisify(fs.readdir);
const readFile = promisify(fs.readFile);
const writeFile = promisify(fs.writeFile);

async function initDirectories() {
  const paths = Object.values(CONFIG.output).map((p) =>
    path.join(CONFIG.output.root, p)
  );

  await Promise.all(
    paths.map(async (p) => {
      if (!fs.existsSync(p)) {
        await fs.promises.mkdir(p, { recursive: true });
      }
    })
  );
}

// ===================== æµå¼æ•°æ®åŠ è½½ =====================
class StreamLoader {
  static async *tensorIterator(tensor) {
    const size = tensor.size;
    for (let i = 0; i < size; i += CONFIG.performance.chunkSize) {
      const end = Math.min(i + CONFIG.performance.chunkSize, size);
      const slice = tensor.reshape([size]).slice([i], [end - i]);
      const data = await slice.data();
      yield data;
      tf.dispose(slice);
      await new Promise((resolve) => setImmediate(resolve));
    }
  }

  static async processTensor(tensor) {
    const stats = {
      min: Infinity,
      max: -Infinity,
      sum: 0,
      count: 0,
    };

    for await (const chunk of this.tensorIterator(tensor)) {
      const chunkStats = chunk.reduce(
        (acc, val) => ({
          min: Math.min(acc.min, val),
          max: Math.max(acc.max, val),
          sum: acc.sum + val,
          count: acc.count + 1,
        }),
        { ...stats }
      );

      Object.assign(stats, chunkStats);
    }

    return {
      ...stats,
      mean: stats.sum / stats.count,
      range: stats.max - stats.min,
    };
  }
}

// ===================== é«˜æ€§èƒ½å¯è§†åŒ– =====================
class HistogramGenerator {
  static async createComparison(gtTensor, predTensor, filename) {
    // å¹¶è¡Œè®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    const [gtStats, predStats] = await Promise.all([
      StreamLoader.processTensor(gtTensor),
      StreamLoader.processTensor(predTensor),
    ]);

    // åŠ¨æ€åˆ†ç®±ç­–ç•¥
    const binWidth = this.calculateBinWidth(gtStats, predStats);
    const binCount = Math.min(
      Math.ceil(
        (Math.max(gtStats.max, predStats.max) -
          Math.min(gtStats.min, predStats.min)) /
          binWidth
      ),
      CONFIG.performance.maxBins
    );

    // åˆ›å»ºCanvas
    const canvas = createCanvas(2400, 1200);
    const ctx = canvas.getContext("2d");
    this.setupCanvas(ctx, canvas);

    // æµå¼æ„å»ºç›´æ–¹å›¾
    await this.drawHistogram(ctx, gtTensor, gtStats, binWidth, binCount, "gt");
    await this.drawHistogram(
      ctx,
      predTensor,
      predStats,
      binWidth,
      binCount,
      "pred"
    );

    // æ·»åŠ æ ‡æ³¨
    this.drawAnnotations(ctx, canvas, gtStats, predStats, binWidth);

    // ä¿å­˜è¾“å‡º
    await this.saveOutput(canvas, filename);
  }

  static calculateBinWidth(gtStats, predStats) {
    const n = Math.sqrt(gtStats.count + predStats.count);
    const range = Math.max(gtStats.range, predStats.range);
    return (2 * (gtStats.mean + predStats.mean)) / Math.cbrt(n);
  }

  static setupCanvas(ctx, canvas) {
    ctx.fillStyle = "#FFFFFF";
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    ctx.font = `bold ${12 * (canvas.width / 1200)}px Arial`;
    ctx.textBaseline = "top";
  }

  static async drawHistogram(ctx, tensor, stats, binWidth, binCount, type) {
    const bins = new Uint32Array(binCount);
    const minVal = Math.min(stats.min, stats.min);

    for await (const chunk of StreamLoader.tensorIterator(tensor)) {
      chunk.forEach((value) => {
        const bin = Math.min(
          Math.floor((value - minVal) / binWidth),
          binCount - 1
        );
        if (bin >= 0) bins[bin]++;
      });
    }

    const maxCount = Math.max(...bins);
    const color =
      type === "gt" ? "rgba(255,99,132,0.6)" : "rgba(54,162,235,0.6)";

    ctx.fillStyle = color;
    const barWidth = (ctx.canvas.width - 200) / binCount;

    bins.forEach((count, i) => {
      const height = (count / maxCount) * (ctx.canvas.height - 200);
      ctx.fillRect(
        100 + i * barWidth,
        ctx.canvas.height - 100 - height,
        barWidth * 0.8,
        height
      );
    });
  }

  static drawAnnotations(ctx, canvas, gtStats, predStats, binWidth) {
    ctx.fillStyle = "#333333";
    ctx.textAlign = "center";
    ctx.fillText("Weight Value Distribution", canvas.width / 2, 50);

    // Xè½´æ ‡æ³¨
    Array.from({ length: 5 }).forEach((_, i) => {
      const x = 100 + (i * (canvas.width - 200)) / 4;
      const value = (gtStats.min + i * binWidth * 5).toFixed(2);
      ctx.fillText(value, x, canvas.height - 70);
    });

    // å›¾ä¾‹
    ctx.fillStyle = "#666666";
    ctx.fillRect(150, 100, 300, 120);
    ctx.fillStyle = "#FFFFFF";
    ctx.fillText(`Ground Truth (Î¼=${gtStats.mean.toFixed(4)})`, 300, 120);
    ctx.fillText(`Predicted (Î¼=${predStats.mean.toFixed(4)})`, 300, 150);
  }

  static async saveOutput(canvas, filename) {
    const buffer = canvas.toBuffer("image/png", {
      compressionLevel: 3,
      filters: canvas.PNG_FILTER_NONE,
    });

    await writeFile(filename, buffer);
    console.log(`ğŸ“ˆ ç›´æ–¹å›¾å·²ä¿å­˜: ${filename}`);
  }
}

// ===================== åˆ†æå¼•æ“ =====================
class AnalysisEngine {
  constructor() {
    this.model = null;
  }

  async initialize() {
    await initDirectories();
    this.model = await tf.loadLayersModel(CONFIG.modelPath);
    console.log("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ | æ¨¡å‹åŠ è½½æˆåŠŸ");
  }

  async execute() {
    try {
      const [images, offsets, weights] = await Promise.all([
        this.loadDataset("lrImages"),
        this.loadDataset("offsets"),
        this.loadDataset("gtWeights"),
      ]);

      const sampleId = Array.from(images.keys())[0];
      console.log(`ğŸ” åˆ†ææ ·æœ¬: ${sampleId}`);

      const { gtWeights, predWeights } = await this.processSample(
        images.get(sampleId),
        offsets.get(sampleId),
        weights.get(sampleId)
      );

      await this.generateReports(gtWeights, predWeights);
      await this.cleanup([gtWeights, predWeights]);
    } catch (error) {
      console.error("â€¼ï¸ åˆ†ææµç¨‹å¼‚å¸¸:", error);
      process.exit(1);
    }
  }

  async loadDataset(type) {
    const dir = CONFIG.directories[type];
    const files = (await readDir(dir)).filter((f) => f.endsWith(".bin"));

    const dataset = new Map();
    await Promise.all(
      files.map(async (file) => {
        const tensor = await this.loadTensor(path.join(dir, file));
        dataset.set(path.parse(file).name, tensor);
      })
    );

    return dataset;
  }

  async loadTensor(filePath) {
    const buffer = await readFile(filePath);
    const header = {
      height: buffer.readUInt32LE(0),
      width: buffer.readUInt32LE(4),
      channels: buffer.readUInt32LE(8),
    };

    const data = new Float32Array(
      buffer.buffer,
      buffer.byteOffset + 12,
      (buffer.length - 12) / 4
    );

    return tf.tensor3d(data, [header.height, header.width, header.channels]);
  }

  async processSample(image, offset, gt) {
    const pred = this.model
      .predict([image.expandDims(0), offset.expandDims(0)])
      .squeeze();

    return {
      gtWeights: gt,
      predWeights: pred,
    };
  }

  async generateReports(gt, pred) {
    const histPath = path.join(
      CONFIG.output.root,
      CONFIG.output.histograms,
      "weight_comparison.png"
    );

    await HistogramGenerator.createComparison(gt, pred, histPath);
    console.log("ğŸ“Š å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆ");
  }

  async cleanup(tensors) {
    await Promise.all(tensors.map((t) => tf.dispose(t) || true));
    console.log("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ");
  }
}

// ===================== æ‰§è¡Œå…¥å£ =====================
(async () => {
  try {
    const engine = new AnalysisEngine();
    await engine.initialize();
    await engine.execute();
    console.log("ğŸ åˆ†ææµç¨‹æˆåŠŸç»“æŸ");
  } catch (error) {
    console.error("â€¼ï¸ ç³»ç»Ÿçº§é”™è¯¯:", error);
    process.exit(2);
  }
})();
