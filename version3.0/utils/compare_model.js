// bicubic_weight_comparison.js
const tf = require("@tensorflow/tfjs-node");
const fs = require("fs");
const path = require("path");
const { promisify } = require("util");
const PNG = require("pngjs").PNG;

// ===================== é…ç½® =====================
const learn_rate = "1e-4-20"; // å¯é…ç½®ä¸ºå‘½ä»¤è¡Œå‚æ•°
const OUTPUT_DIR = path.join("cp_model", learn_rate);

// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
if (!fs.existsSync(OUTPUT_DIR)) {
  fs.mkdirSync(OUTPUT_DIR, { recursive: true });
}

const CONFIG = {
  metadataPath: "./data/test/metadata.json",
  directories: {
    lrImages: "./data/test/X/",
    offsets: "./data/test/offset/",
    gtWeights: "./data/test/Y/",
  },
  modelPath: `file://./model/${learn_rate}/model.json`,
  output: {
    sampleWeights: path.join(OUTPUT_DIR, "weight_sample.png"),
    gtHistogram: path.join(OUTPUT_DIR, "gt_weights_hist.png"),
    predHistogram: path.join(OUTPUT_DIR, "pred_weights_hist.png"),
    comparisonTable: path.join(OUTPUT_DIR, "comparison.txt"),
  },
};

// ===================== å·¥å…·å‡½æ•° =====================
// ===================== å·¥å…·å‡½æ•° =====================
const readDir = promisify(fs.readdir);
const readFile = promisify(fs.readFile);
const writeFile = promisify(fs.writeFile);

async function loadTensorWithHeader(filePath) {
  const buffer = await fs.promises.readFile(filePath);

  const header = {
    height: buffer.readUInt32LE(0),
    width: buffer.readUInt32LE(4),
    channels: buffer.readUInt32LE(8),
  };

  const dataBuffer = buffer.slice(12);
  const float32Data = new Float32Array(
    dataBuffer.buffer,
    dataBuffer.byteOffset,
    dataBuffer.byteLength / 4
  );

  return {
    tensor: tf.tensor3d(float32Data, [
      header.height,
      header.width,
      header.channels,
    ]),
    header,
  };
}

function validateTensor(tensor, header, filename) {
  const expectedSize = header.height * header.width * header.channels;
  if (tensor.size !== expectedSize) {
    throw new Error(
      `æ•°æ®éªŒè¯å¤±è´¥ ${filename}\né¢„æœŸ: ${expectedSize}\nå®é™…: ${tensor.size}`
    );
  }
}

// ===================== æ ¸å¿ƒé€»è¾‘ =====================
class WeightComparator {
  constructor(config) {
    this.config = config;
    this.model = null;
    this.metadata = null;
  }

  async initialize() {
    this.metadata = JSON.parse(await readFile(this.config.metadataPath));
    this.model = await tf.loadLayersModel(this.config.modelPath);
    console.log("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
  }

  async loadDataset() {
    const loadData = async (dir) => {
      const files = await readDir(dir);
      const tensorMap = new Map();

      for (const file of files.filter((f) => f.endsWith(".bin"))) {
        const filePath = path.join(dir, file);
        const { tensor, header } = await loadTensorWithHeader(filePath);
        validateTensor(tensor, header, file);
        tensorMap.set(path.parse(file).name, tensor);
      }
      return tensorMap;
    };

    const [images, offsets, weights] = await Promise.all([
      loadData(this.config.directories.lrImages),
      loadData(this.config.directories.offsets),
      loadData(this.config.directories.gtWeights),
    ]);

    return { images, offsets, weights };
  }

  async compareWeights(gtTensor, predTensor) {
    console.log("\nğŸ”¬ å¼€å§‹æƒé‡å¯¹æ¯”åˆ†æ");

    // å…¨å±€è¯¯å·®åˆ†æ
    const mse = tf.losses.meanSquaredError(gtTensor, predTensor);
    console.log(`ğŸ“‰ å…¨å±€MSE: ${mse.dataSync()[0].toExponential(3)}`);
    tf.dispose(mse);

    // é€šé“çº§å¯¹æ¯”
    const channelErrors = [];
    for (let c = 0; c < 16; c++) {
      const gtChannel = gtTensor.slice([0, 0, c], [-1, -1, 1]);
      const predChannel = predTensor.slice([0, 0, c], [-1, -1, 1]);
      const channelMSE = tf.losses.meanSquaredError(gtChannel, predChannel);
      channelErrors.push(channelMSE.dataSync()[0]);
      tf.dispose([gtChannel, predChannel, channelMSE]);
    }
    console.log("ğŸ“Š å„é€šé“MSE:");
    channelErrors.forEach((err, i) =>
      console.log(`é€šé“ ${i.toString().padStart(2)}: ${err.toExponential(3)}`)
    );

    // å¯è§†åŒ–å¯¹æ¯”
    await this.generateHistograms(gtTensor, predTensor);
    await this.samplePixelComparison(gtTensor, predTensor);
  }

  async generateHistograms(gtTensor, predTensor) {
    // åˆ›å»ºç›´æ–¹å›¾ç›®å½•
    const histDir = path.join(OUTPUT_DIR, "histograms");
    if (!fs.existsSync(histDir)) {
      fs.mkdirSync(histDir, { recursive: true });
    }

    await this.createHistogram(
      gtTensor,
      path.join(histDir, "gt_histogram.png")
    );
    await this.createHistogram(
      predTensor,
      path.join(histDir, "pred_histogram.png")
    );
  }

  async createHistogram(tensor, filename) {
    const data = await tensor.data();
    const bins = new Array(20).fill(0);

    data.forEach((v) => {
      const bin = Math.min(Math.floor(v * 20), 19);
      bins[bin]++;
    });

    const png = new PNG({ width: 800, height: 400, colorType: 2 });
    const maxCount = Math.max(...bins);

    bins.forEach((count, i) => {
      const barHeight = (count / maxCount) * 400;
      for (let y = 399; y >= 400 - barHeight; y--) {
        for (let x = i * 40; x < (i + 1) * 40; x++) {
          const idx = (y * 800 + x) * 3;
          png.data[idx] = 255; // çº¢è‰²é€šé“
          png.data[idx + 1] = 0; // ç»¿è‰²é€šé“
          png.data[idx + 2] = 0; // è“è‰²é€šé“
        }
      }
    });

    await new Promise((resolve) =>
      png.pack().pipe(fs.createWriteStream(filename)).on("finish", resolve)
    );
  }

  // ä¿®æ”¹ samplePixelComparison æ–¹æ³•ä¸­çš„è¿™éƒ¨åˆ†
  async samplePixelComparison(gtTensor, predTensor) {
    const sampleCoord = {
      x: Math.floor(gtTensor.shape[1] / 2),
      y: Math.floor(gtTensor.shape[0] / 2),
    };

    // ä¿®å¤æ•°ç»„è®¿é—®æ–¹å¼
    const gtValues = gtTensor
      .slice([sampleCoord.y, sampleCoord.x, 0], [1, 1, 16])
      .arraySync()
      .flat(2);
    const predValues = predTensor
      .slice([sampleCoord.y, sampleCoord.x, 0], [1, 1, 16])
      .arraySync()
      .flat(2);

    console.log(`\nğŸ” ä¸­å¿ƒç‚¹ (${sampleCoord.x},${sampleCoord.y}) æƒé‡å¯¹æ¯”:`);
    console.log("â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    console.log("â”‚ é€šé“ â”‚ çœŸå®æƒé‡          â”‚ é¢„æµ‹æƒé‡          â”‚ å·®å¼‚(%)   â”‚");
    console.log("â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

    gtValues.forEach((gt, i) => {
      const pred = predValues[i];
      const diff = (((pred - gt) / (Math.abs(gt) + 1e-8)) * 100).toFixed(2);
      console.log(
        `â”‚ ${i.toString().padStart(2)}  â”‚ ${gt
          .toExponential(4)
          .padEnd(15)} â”‚ ` +
          `${pred.toExponential(4).padEnd(15)} â”‚ ${diff.padStart(7)}% â”‚`
      );
    });
    console.log("â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    // ä¿å­˜å¯¹æ¯”ç»“æœåˆ°æ–‡ä»¶
    const tableContent = [
      "â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
      "â”‚ é€šé“ â”‚ çœŸå®æƒé‡          â”‚ é¢„æµ‹æƒé‡          â”‚ å·®å¼‚(%)   â”‚",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
      ...gtValues.map((gt, i) => {
        const pred = predValues[i];
        const diff = (((pred - gt) / (Math.abs(gt) + 1e-8)) * 100).toFixed(2);
        return (
          `â”‚ ${i.toString().padStart(2)}  â”‚ ${gt
            .toExponential(4)
            .padEnd(15)} â”‚ ` +
          `${pred.toExponential(4).padEnd(15)} â”‚ ${diff.padStart(7)}% â”‚`
        );
      }),
      "â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
    ].join("\n");

    await writeFile(CONFIG.output.comparisonTable, tableContent);
    console.log(`ğŸ“ å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜è‡³: ${CONFIG.output.comparisonTable}`);
  }
  async visualizeSampleWeights(tensor) {
    // åˆ›å»ºå¯è§†åŒ–ç›®å½•
    const visDir = path.join(OUTPUT_DIR, "visualizations");
    if (!fs.existsSync(visDir)) {
      fs.mkdirSync(visDir, { recursive: true });
    }

    const outputPath = path.join(visDir, "weight_samples");
    if (!fs.existsSync(outputPath)) {
      fs.mkdirSync(outputPath);
    }

    // ä¿å­˜å¤šä¸ªé€šé“çš„å¯è§†åŒ–ç»“æœ
    for (let c = 0; c < 3; c++) {
      // ç¤ºä¾‹ä¿å­˜å‰3ä¸ªé€šé“
      const channel = tensor.slice([0, 0, c], [-1, -1, 1]);
      const png = await this.tensorToPNG(channel);
      await writeFile(path.join(outputPath, `channel_${c}.png`), png);
      tf.dispose(channel);
    }
    console.log(`ğŸ–¼ï¸ å¤šé€šé“å¯è§†åŒ–å·²ä¿å­˜è‡³: ${outputPath}`);
  }

  async tensorToPNG(tensor) {
    const data = await tensor.data();
    const [height, width] = tensor.shape;

    const png = new PNG({ width, height, colorType: 2 });
    data.forEach((v, i) => {
      const val = Math.min(255, Math.max(0, v * 255));
      png.data[i * 3] = val; // R
      png.data[i * 3 + 1] = val; // G
      png.data[i * 3 + 2] = val; // B
    });

    return PNG.sync.write(png);
  }
  async execute() {
    try {
      await this.initialize();
      const { images, offsets, weights } = await this.loadDataset();

      const [sampleId] = Array.from(images.keys());
      const inputTensor = images.get(sampleId).expandDims(0);
      const offsetTensor = offsets.get(sampleId).expandDims(0);
      const gtTensor = weights.get(sampleId);

      const predTensor = this.model
        .predict([inputTensor, offsetTensor])
        .squeeze();
      console.log("ğŸ§  é¢„æµ‹å®Œæˆï¼Œå¼€å§‹åˆ†æ...");

      await this.compareWeights(gtTensor, predTensor);
      await this.visualizeSampleWeights(predTensor);

      tf.dispose([inputTensor, offsetTensor, gtTensor, predTensor]);
    } catch (error) {
      console.error("â€¼ï¸ æ‰§è¡Œå¤±è´¥:", error.message);
    }
  }

  async visualizeSampleWeights(tensor) {
    const sample = tensor.slice([0, 0, 0], [100, 100, 16]);
    const firstChannel = sample.slice([0, 0, 0], [100, 100, 1]);

    const png = new PNG({ width: 100, height: 100, colorType: 2 });
    const data = await firstChannel.data();

    data.forEach((v, i) => {
      const val = Math.min(255, Math.max(0, v * 255));
      png.data[i * 3] = val; // R
      png.data[i * 3 + 1] = val; // G
      png.data[i * 3 + 2] = val; // B
    });

    await new Promise((resolve) =>
      png
        .pack()
        .pipe(fs.createWriteStream(this.config.output.sampleWeights))
        .on("finish", resolve)
    );
    console.log(`ğŸ–¼ï¸ æƒé‡é‡‡æ ·å›¾å·²ä¿å­˜è‡³: ${this.config.output.sampleWeights}`);
  }
}

// ===================== æ‰§è¡Œå…¥å£ =====================
(async () => {
  try {
    // äºŒæ¬¡ç¡®è®¤è¾“å‡ºç›®å½•
    if (!fs.existsSync(OUTPUT_DIR)) {
      fs.mkdirSync(OUTPUT_DIR, { recursive: true });
      console.log(`ğŸ“‚ å·²åˆ›å»ºè¾“å‡ºç›®å½•: ${OUTPUT_DIR}`);
    }

    const comparator = new WeightComparator(CONFIG);
    await comparator.execute();
    console.log("ğŸ ç¨‹åºæ‰§è¡Œå®Œæˆ");

    // æ‰“å¼€ç»“æœç›®å½•ï¼ˆä»…é™macOSï¼‰
    if (process.platform === "darwin") {
      require("child_process").exec(`open ${path.resolve(OUTPUT_DIR)}`);
    }
  } catch (error) {
    console.error("â€¼ï¸ åˆå§‹åŒ–å¤±è´¥:", error.message);
    process.exit(1);
  }
})();
