const tf = require("@tensorflow/tfjs-node");
const fs = require("fs");
const path = require("path");
const { promisify } = require("util");
const readFile = promisify(fs.readFile);
const PNG = require("pngjs").PNG; // ç”¨äºå¯è§†åŒ–

// ===================== é…ç½® =====================
const TEST_METADATA = "./data/test/metadata.json";
const TEST_DIR = {
  X_IMAGE: "./data/test/X/",
  X_OFFSET: "./data/test/offset/",
  Y_GT: "./data/test/Y/", // å¯é€‰çš„çœŸå®æƒé‡
};
const MODEL_PATH = "file://./model/1e-4/model.json";

// ===================== æ”¹è¿›åçš„æ•°æ®åŠ è½½å‡½æ•° =====================
async function loadDynamicTensor(dirPath) {
  const files = await promisify(fs.readdir)(dirPath);
  const tensorMap = new Map();

  for (const file of files) {
    if (!file.endsWith(".bin")) continue;

    const filePath = path.join(dirPath, file);
    const { tensor, header } = await loadTensorWithHeader(filePath);

    // éªŒè¯æ•°æ®å®Œæ•´æ€§
    validateTensorData(file, tensor, header);

    tensorMap.set(path.parse(file).name, tensor);
  }
  return tensorMap;
}

async function loadTensorWithHeader(filePath) {
  const buffer = await fs.promises.readFile(filePath);

  // è¯»å–å¤´ä¿¡æ¯ï¼ˆå‰12å­—èŠ‚ï¼‰
  const header = {
    height: buffer.readUInt32LE(0),
    width: buffer.readUInt32LE(4),
    channels: buffer.readUInt32LE(8),
  };

  // æå–æ•°æ®éƒ¨åˆ†ï¼ˆä»ç¬¬12å­—èŠ‚å¼€å§‹ï¼‰
  const dataBuffer = buffer.slice(12);
  const float32Data = new Float32Array(
    dataBuffer.buffer,
    dataBuffer.byteOffset,
    dataBuffer.byteLength / 4
  );

  return {
    tensor: tf.tensor3d(float32Data, [
      header.height,
      header.width,
      header.channels,
    ]),
    header,
  };
}

function validateTensorData(filename, tensor, header) {
  // éªŒè¯æ•°æ®å°ºå¯¸
  const expectedSize = header.height * header.width * header.channels;
  const actualSize = tensor.size;

  if (actualSize !== expectedSize) {
    throw new Error(`æ•°æ®å°ºå¯¸éªŒè¯å¤±è´¥ï¼š${filename}
      é¢„æœŸï¼š${expectedSize} (${header.height}x${header.width}x${header.channels})
      å®é™…ï¼š${actualSize}`);
  }

  // æ·»åŠ å…¶ä»–éªŒè¯è§„åˆ™ï¼ˆå¯é€‰ï¼‰
  if (header.height <= 0 || header.width <= 0 || header.channels <= 0) {
    throw new Error(`éæ³•å¤´ä¿¡æ¯ï¼š${filename} ${JSON.stringify(header)}`);
  }
}

// ===================== æµ‹è¯•å‡½æ•° =====================
async function testModel() {
  try {
    const model = await tf.loadLayersModel(MODEL_PATH);
    console.log("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ");

    // åŠ è½½æµ‹è¯•æ•°æ®
    const [testImages, testOffsets] = await Promise.all([
      loadDynamicTensor(TEST_DIR.X_IMAGE),
      loadDynamicTensor(TEST_DIR.X_OFFSET),
    ]);

    const testId = Array.from(testImages.keys())[0];
    const X_image = testImages.get(testId).expandDims(0);
    const X_offset = testOffsets.get(testId).expandDims(0);

    // æ‰§è¡Œé¢„æµ‹
    const predY = model.predict([X_image, X_offset]);
    console.log("ğŸ“Š é¢„æµ‹å½¢çŠ¶:", predY.shape);

    // åˆ†æ‰¹éªŒè¯æƒé‡å’Œ
    await validateSumWeights(predY);

    // æŠ½æ ·å¯è§†åŒ–
    await visualizeWeights(predY.squeeze());
    // é¢„æµ‹åè°ƒç”¨ï¼ˆç¤ºä¾‹æŸ¥çœ‹ä¸­å¿ƒç‚¹ï¼‰
    const centerX = Math.floor(predY.shape[2] / 2);
    const centerY = Math.floor(predY.shape[1] / 2);
    await inspectPixelWeights(predY, centerX, centerY);

    // ä¹Ÿå¯ä»¥æŸ¥çœ‹è¾¹ç¼˜ç‚¹
    await inspectPixelWeights(predY, 0, 0);
    // é‡Šæ”¾é¢„æµ‹ç»“æœ
    tf.dispose(predY);
  } catch (error) {
    console.error("â€¼ï¸ æµ‹è¯•å¤±è´¥:", error);
  }
}
async function inspectPixelWeights(predY, x = 100, y = 100) {
  let weights = null;
  try {
    // å¢å¼ºè¾“å…¥éªŒè¯
    if (!predY || predY.isDisposed) {
      console.log("âš ï¸ è¾“å…¥å¼ é‡æ— æ•ˆæˆ–å·²é‡Šæ”¾");
      return;
    }

    // ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
    const [_, H, W, C] = predY.shape || [];
    if (x < 0 || x >= (W || 0) || y < 0 || y >= (H || 0)) {
      console.log(
        `âŒ åæ ‡è¶…å‡ºèŒƒå›´ (æœ€å¤§åæ ‡: X=${(W || 0) - 1}, Y=${(H || 0) - 1})`
      );
      return;
    }

    // æå–æŒ‡å®šä½ç½®æƒé‡
    weights = predY.slice([0, y, x, 0], [1, 1, 1, 16]).squeeze();
    const weightValues = Array.from(weights.dataSync());

    // æ ¼å¼åŒ–ä¸ºç§‘å­¦è®¡æ•°æ³•å’ŒåŸå§‹å€¼
    console.log(`\nğŸ” åƒç´  (X=${x}, Y=${y}) çš„ 16 ä¸ªæƒé‡å€¼ï¼š`);
    console.log("â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    console.log("â”‚ é€šé“ â”‚ åŸå§‹å€¼                â”‚ ç§‘å­¦è®¡æ•°æ³•      â”‚");
    console.log("â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    weightValues.forEach((v, i) => {
      console.log(
        `â”‚ ${i.toString().padStart(2)}  â”‚ ${v.toFixed(10).padEnd(20)} â”‚ ${v
          .toExponential(4)
          .padEnd(15)} â”‚`
      );
    });
    console.log("â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

    // éªŒè¯æƒé‡å’Œ
    const sum = weightValues.reduce((a, b) => a + b, 0);
    console.log(`\nÎ£ æƒé‡å’Œ: ${sum.toFixed(8)} (ç†è®ºåº”ä¸º 1.0)`);

    // æ£€æŸ¥è´Ÿå€¼
    const negativeWeights = weightValues.filter((v) => v < 0);
    if (negativeWeights.length > 0) {
      console.log(`âš ï¸ å‘ç° ${negativeWeights.length} ä¸ªè´Ÿæƒé‡å€¼`);
    }
  } catch (error) {
    console.error("â€¼ï¸ æƒé‡æ£€æŸ¥å¤±è´¥:", error.message);
  } finally {
    // å®‰å…¨æ¸…ç†å†…å­˜
    if (weights && !weights.isDisposed) {
      tf.dispose(weights);
    }
  }
}

// ===================== åˆ†æ‰¹éªŒè¯å‡½æ•° =====================
async function validateSumWeights(predY) {
  const [H, W, C] = predY.shape.slice(1);

  let totalSum = 0;
  const batchSize = 128;

  for (let h = 0; h < H; h += batchSize) {
    const hEnd = Math.min(h + batchSize, H);
    for (let w = 0; w < W; w += batchSize) {
      const wEnd = Math.min(w + batchSize, W);
      const patch = predY.slice([0, h, w, 0], [1, hEnd - h, wEnd - w, C]);

      const sum = patch.sum(-1).dataSync();
      const patchAvg = sum.reduce((a, b) => a + b, 0) / sum.length;
      totalSum += patchAvg * (hEnd - h) * (wEnd - w);

      tf.dispose([patch, sum]);
      await tf.nextFrame();
    }
  }

  const globalAvg = totalSum / (H * W);
  console.log(`å…¨å±€æƒé‡å¹³å‡å€¼: ${globalAvg.toFixed(6)}`);
}

// ===================== å¯è§†åŒ–å·¥å…· =====================
async function visualizeWeights(weightsTensor) {
  // æŠ½æ · 100x100 åŒºåŸŸ
  const sample = weightsTensor.slice([0, 0, 0], [100, 100, 16]);
  const firstChannel = sample.slice([0, 0, 0], [100, 100, 1]);

  await tensorToPNG(firstChannel, "weight_sample.png");
  tf.dispose([sample, firstChannel]);
}

async function tensorToPNG(tensor, filename) {
  const data = await tensor.data();
  const [height, width] = tensor.shape;

  const png = new PNG({
    width,
    height,
    colorType: 2, // RGB
  });

  for (let i = 0; i < data.length; i++) {
    const val = Math.min(255, Math.max(0, data[i] * 255));
    png.data[i * 3] = val; // R
    png.data[i * 3 + 1] = val; // G
    png.data[i * 3 + 2] = val; // B
  }

  return new Promise((resolve) => {
    png.pack().pipe(fs.createWriteStream(filename)).on("finish", resolve);
  });
}

// å¯åŠ¨æµ‹è¯•
testModel();
